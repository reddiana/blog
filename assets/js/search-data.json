{
  
    
        "post0": {
            "title": "Container Graceful Shutdown",
            "content": "Graceful Shutdown . 문제점 . 롱트랜잭션 실행 중일 때 shutdown 한다면? | 서비스 업데이트 등의 상황으로 k8s가 pod 종료 시도할 때 | pod가 처리 중인 상태에서 강제로 kill 될 가능성 농후 | . 1안) SIGTERM에 대한 처리 구현 . Python Conatiner . signal trap으로 구현 | . RESTful API Contaner . Supervisord 설정 . stopsignal=HUP stopwaitsecs=10 . | uWSGI . 뭔짓을 해도 python에서 trap을 하지 못한다 | 그나마 graceful하게 reload은 한다 | . | . 시나리오1 . docker stop하면 | Supervisord에서 HUP 보내고 | uWSGI는 graceful reload (이뭐병) | (결과적으로 uWSGI랑 상관없이) Supervisord는 10초 기다렸다 kill all | 아직 안 죽었으면 docker는 time 기다리고 kill | 시나리오2 . 그냥 K8s에서 terminationGracePeriodSeconds을 길게 준다 | . Signal(IPC) . SIGINT SIGTERM SIGKILL SIGSTOP | Signal (IPC) | . signal can be caught or ignored   내용 . SIGINT | O | interrupt signal | ctrl-c. to provide a mechanism for an orderly, graceful shutdown. “user-initiated happy termination” | . SIGTERM | O | termination signal | to kill the process, gracefully or not, but to first allow it a chance to cleanup. | . SIGKILL | X | kill signal | 프로세스 즉시 죽임!! 최후의 수단!! | . SIGQUIT | O | dump core signal | ctrl- . to provide a mechanism for the user to abort the process. “user-initiated unhappy termination” | . SIGHUP |   | Terminate |   | . SIGSTOP | X | pause signal | resuming via SIGCONT | . SIGCHLD |   |   | Child process terminated, stopped, or continued | . SIGWINCH |   |   |   | . Python에서 처리 . Python에서 처리: signal — Set handlers for asynchronous events | https://codeday.me/ko/qa/20190529/660372.html (Python 2.X) | https://code-examples.net/ko/docs/python~3.7/library/signal | http://blog.kichul.co.kr/2018/01/12/python%EC%97%90%EC%84%9C-signal-%EC%B2%98%EB%A6%AC/ | . uWSGI에서 처리 . Configuring uWSGI for Production Deployment . 아래 설정 절대 안 먹는다. 해도 python에서 signal trap 안된다. . py-call-osafterfork = true . | 하긴 먹어도 쓸데가 없다 . | . | Signals for controlling uWSGI . graceful하게 shutdown하는게 없다!! 나머지는 그냥 immediately kill 해버린다 SIGHUP이 그나마 graceful 한데 reload를 해버린다 | 얼씨구 Windows는 SIGHUP이 없다 | . | . | . Signal Description Convenience command . SIGHUP | gracefully reload all the workers and the master process | --reload | . SIGTERM | brutally reload all the workers and the master process | (use --die-on-term to respect the convention of shutting down the instance) | . SIGINT | immediately kill the entire uWSGI stack | --stop | . SIGQUIT | immediately kill the entire uWSGI stack |   | . Supervisord에서 처리 . https://serverfault.com/questions/386319/is-supervisord-shutting-down-gracefully 야간데… | stopsignal The signal used to kill the program when a stop is requested. This can be any of TERM, HUP, INT, QUIT, KILL, USR1, or USR2. | Default: TERM | Required: No. | . | stopwaitsecs The number of seconds to wait for the OS to return a SIGCHLD to supervisord after the program has been sent a stopsignal. If this number of seconds elapses before supervisord receives a SIGCHLD from the process, supervisord will attempt to kill it with a final SIGKILL. | Default: 10 | Required: No. | . | . | . Docker에서 처리 . Gracefully Stopping Docker Containers | https://codeday.me/ko/qa/20190529/660372.html | . K8s에서 처리 . https://pracucci.com/graceful-shutdown-of-kubernetes-pods.html | Kubernetes: Termination of pods | Kubernetes: Pods lifecycle hooks and termination notice | Kubernetes: Container lifecycle hooks | kubernetes를 이용한 서비스 무중단 배포 terminationGracePeriodSeconds | . | . 2안) 재처리 . 3안) 운영 프로세스로 해결 . shutdown 필요할 시 . request 더이상 발생 안되게 조치 하고 | 충분한 시간 경과 후 (request 처리 중이던 pod가 처리를 모두 마친 후) | shutdown 진행 | python signal trap 예 . app = flask.Blueprint(&#39;app&#39;, __name__) # Graceful Shutdown (signal 처리) 구현 imBusy = [] def graceful_shutdown_handler(signum = None, frame = None): logging.info(&quot;I am dying.. [%s]&quot; % signum) logging.debug(&quot;working [%s]&quot; % imBusy) while len(imBusy) &gt; 0: time.sleep(0.5) logging.info(&quot;Good Bye&quot;) exit(0) # signal 처리 등록 try: signals = [signal.SIGTERM, signal.SIGINT, signal.SIGHUP] except: # Windows에는 signal.SIGHUP 없음 signals = [signal.SIGTERM, signal.SIGINT] for sig in signals: signal.signal(sig, graceful_shutdown_handler) @app.before_app_request def imbusy(): global imBusy imBusy.append(threading.currentThread().name) @app.after_app_request def solong(res): global imBusy logging.debug(&quot;remove [%s]&quot; % threading.currentThread().name) imBusy.remove(threading.currentThread().name) return res .",
            "url": "https://everlearningemployee.github.io/blog/post/container_graceful_shutdown.html",
            "relUrl": "/post/container_graceful_shutdown.html",
            "date": " • Jun 9, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Python 함수 실행시간 측정 decorator",
            "content": "함수 실행시간 측정용 decorator 정의 . def exec_time(original_fn): @wraps(original_fn) def wrapper_fn(*args, **kwargs): int_ln = 70 str_start = &quot;== START [%s] ==&quot; % (original_fn.__name__) int_s1 = int( (int_ln - len(str_start)) / 2 ) int_s2 = int_ln - len(str_start) - int_s1 print(&quot; n&quot; + &quot;=&quot; * int_s1 + str_start + &quot;=&quot; * int_s2) start_time = time.time() result = original_fn(*args, **kwargs) dt = time.time() - start_time str_end = &quot;== END [%s]: working %.4f sec ==&quot; % (original_fn.__name__, dt) int_e1 = int( (int_ln - len(str_end)) / 2 ) int_e2 = int_ln - len(str_end) - int_e1 print(&quot;=&quot; * int_e1 + str_end + &quot;=&quot; * int_e2 + &quot; n&quot;) return result return wrapper_fn . 사용 예 . 코드 . @exec_time def hahahoho(): … 생략 … logger.debug(&#39;long long time&#39;) . 이 때 로그 출력은 다음과 같다 . ========================== START [hahahoho] ========================== … 생략 … [2019-07-15 05:05:35,166] DEBUG long long time ================ END [hahahoho]: working 26.7614 sec ================= .",
            "url": "https://everlearningemployee.github.io/blog/post/Python_decorator_to_measure_the_execution_time_of_methods.html",
            "relUrl": "/post/Python_decorator_to_measure_the_execution_time_of_methods.html",
            "date": " • Jun 9, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "KFServing",
            "content": "KFServing이란 . Kubernetes Custom Resource Definition(CRD) 으로 제공되는 ML Serving 아키텍처 | Serverless로 동작 (내부적으로 Knative 사용) | . . 1. InferenceService . . KFServing의 배포/서비스 단위 (CRD) | api는 Tensorflow V1 HTTP API를 따름 (Out-of-the-box의 경우) | Ensembling, A/B testing, Multi-Arm-Bandits 등은 InferenceService를 조합하여 구현해야함 (단일 InferenceService로는 불가능) Seldon Core와 비교됨 (참고2) | . | . 2. InferenceService 구성요소 . 2.1 Predictor . 필수 | REST API path의 postfix가 :predict | trained model의 serving을 수행 storage에 저장된 trained model을 load하여 서비스 지원하는 storage provider Google Cloud Storage gs:// | S3 Compatible Object Storage s3:// | Azure Blob Storage https:// | Local filesystem file:// | Persistent Volume Claim (PVC) pvc:// | . | . | trained model은 프로비저닝되어 제공되는 이미지(framework)에 따름 제공되는 이미지 프로비저닝 tensorflow | tensorrt | xgboost | sklearn | onnx | pytorch | . | . | . | . 2.2 Transformer . 필수아님 | prediction 또는 explanation의 실행 전/후에 수행될 로직을 탑재 (preprocess/postprocess) → 전처리 / 후처리 용도 | Interceptioon Filter로서 동작 | . 2.3 Explainer . 필수아님 | REST API path의 postfix가 :explain | 제공되는 이미지 프로비저닝 Seldon Alibi | . | . 3. InferenceService 배포 . 방법1: kubectl . kubectl apply -f xxxxx.yaml . | 방법2: Kubeflow Pipelines (Sample) . | 방법3: KFServing Python SDK (Sample) . | . 4. InferenceService 구성요소 유형 . 역할에 따른 구분 Predictor | Transformer | Explainer | . | 이미지 프로비저닝 여부에 따른 구분 Out-of-the-box ← 프로비저닝된 이미지 사용 | Custom | . | . 4.1 Out-of-the-box Predictor . 프로비저닝 이미지를 사용 프로비저닝할 프레임워크(예: tensorflow, pytorch) 명시 필요 (이미지에 대한 기술 X) | . | 모델이 저장된 위치 필요 (storageUri) | . 4.1.1 tensorflow 예제 . 4.1.1.1 manifests: tensorflow.yaml . apiVersion: &quot;serving.kubeflow.org/v1alpha2&quot; kind: &quot;InferenceService&quot; metadata: name: &quot;flowers-sample&quot; spec: default: predictor: tensorflow: storageUri: &quot;gs://kfserving-samples/models/tensorflow/flowers&quot; . 4.1.2 pytorch 예제 . 4.1.2.1 manifests: pytorch.yaml . apiVersion: &quot;serving.kubeflow.org/v1alpha2&quot; kind: &quot;InferenceService&quot; metadata: name: &quot;pytorch-cifar10&quot; spec: default: predictor: pytorch: storageUri: &quot;gs://kfserving-samples/models/pytorch/cifar10/&quot; modelClassName: &quot;Net&quot; . 4.2 Custom Predictor . 프로비저닝 이미지를 사용하지 않고 Custom 이미지를 사용 | . 4.2.1 Flask Hello World 예제 . 4.2.1.1 manifests: custom.yaml . apiVersion: serving.kubeflow.org/v1alpha2 kind: InferenceService metadata: labels: controller-tools.k8s.io: &quot;1.0&quot; name: custom-sample spec: default: predictor: custom: container: image: sds.redii.net/sample/custom-sample env: - name: GREETING_TARGET value: &quot;Python KFServing Sample&quot; . 4.2.1.2 Dockerfile . # ... 선략 ... CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 app:app . 4.2.1.3 application: app.py . import os from flask import Flask app = Flask(__name__) @app.route(&#39;/v1/models/custom-sample:predict&#39;) def hello_world(): greeting_target = os.environ.get(&#39;GREETING_TARGET&#39;, &#39;World&#39;) return &#39;Hello {}! n&#39;.format(greeting_target) if __name__ == &quot;__main__&quot;: app.run(debug=True, host=&#39;0.0.0.0&#39;, port=int(os.environ.get(&#39;PORT&#39;, 8080))) . 4.2.2 kfserving-custom-model 예제 . 4.2.2.1 manifests: custom.yaml . apiVersion: serving.kubeflow.org/v1alpha2 kind: InferenceService metadata: labels: controller-tools.k8s.io: &quot;1.0&quot; name: kfserving-custom-model spec: default: predictor: custom: container: image: {username}/kfserving-custom-model . 4.2.2.2 Dockerfile . # ... 선략 ... COPY model.py imagenet_classes.txt ./ CMD [&quot;python&quot;, &quot;model.py&quot;] . 4.2.2.3 application: model.py . kfserving.KFModel을 상속받고 load()와 predict()를 구현함 | load()를 미리 호출하여 model을 restore한 후, 서버를 start() | . import kfserving from typing import List, Dict class KFServingSampleModel(kfserving.KFModel): def __init__(self, name: str): super().__init__(name) self.name = name self.ready = False def load(self): # model load 코드 생략 self.model = model self.ready = True def predict(self, request: Dict) -&gt; Dict: inputs = request[&quot;instances&quot;] # predict 코드 생략 return {&quot;predictions&quot;: results} if __name__ == &quot;__main__&quot;: model = KFServingSampleModel(&quot;kfserving-custom-model&quot;) model.load() kfserving.KFServer(workers=1).start([model]) . 4.3 Transformer . 4.3.1 Image Transformer with PyTorch Predictor 예제 . 4.3.1.1 manifests: image_transformer.yaml . apiVersion: serving.kubeflow.org/v1alpha2 kind: InferenceService metadata: name: transformer-cifar10 spec: default: transformer: custom: container: image: gcr.io/kubeflow-ci/kfserving/image-transformer:latest name: user-container predictor: pytorch: modelClassName: Net storageUri: gs://kfserving-samples/models/pytorch/cifar10 . 4.3.1.2 Dockerfile . # ... 선략 ... ENTRYPOINT [&quot;python&quot;, &quot;-m&quot;, &quot;image_transformer&quot;] . 4.3.1.3 application: image_transformer.py . kfserving.KFModel을 상속받고 preprocess()와 postprocess()를 구현함 | . def image_transform(instance): ...생략... return res.tolist() class ImageTransformer(kfserving.KFModel): def __init__(self, name: str, predictor_host: str): super().__init__(name) self.predictor_host = predictor_host def preprocess(self, inputs: Dict) -&gt; Dict: return {&#39;instances&#39;: [image_transform(instance) for instance in inputs[&#39;instances&#39;]]} def postprocess(self, inputs: List) -&gt; List: return inputs if __name__ == &quot;__main__&quot;: transformer = ImageTransformer(args.model_name, predictor_host=args.predictor_host) kfserver = kfserving.KFServer() kfserver.start(models=[transformer]) . 5. KFServing Python SDK . 5.1 Model / Server . “4.2 Custom Predictor / 4.2.2 kfserving-custom-model 예제” 및 “4.3 Transformer” 참조 | . 5.2 Client . “3. InferenceService 배포 / 방법3: KFServing Python SDK (Sample)” 참조 | . 참고1: TensorFlow Model을 Save하는 방법 . 체크포인트 . training 중간과 training 마지막에 체크포인트(checkpoint)를 저장 다시 training 하지 않고 모델을 재사용하거나 | training 과정이 중지된 경우 이어서 training을 진행 가능 | . | .ckpt 파일 모델의 가중치를 포함하는 하나 이상의 샤드(shard) | 가중치가 어느 샤드에 저장되어 있는지를 나타내는 인덱스 파일 | 모델 전체를 저장하지 않음 → 모델 구조는 저장하지 않음 | . | . HDF5 (Hierarchical Data Format) . 모델 전체를 저장 | .h5 또는 .hdf5 파일 가중치 값 | 모델 설정(구조) | 옵티마이저 설정 | . | . TensorFlow SavedModel . language-neutral format to save machine-learned models → Tensorflow Serving 등에서 사용 | 모델 전체를 저장 | Ref: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/saved_model#tensorflow-savedmodel | 저장 예제 코드 | . export_dir = ... ... builder = tf.saved_model.builder.SavedModelBuilder(export_dir) with tf.Session(graph=tf.Graph()) as sess: ... builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.TRAINING], signature_def_map=foo_signatures, assets_collection=foo_assets) ... with tf.Session(graph=tf.Graph()) as sess: ... builder.add_meta_graph([&quot;bar-tag&quot;, &quot;baz-tag&quot;]) ... builder.save() . SignatureDef로 다음 항목을 정의 method_name | inputs: 입력 tensor의 이름, dtype, shape을 정의 | outpus: 출력 tensor의 이름, dtype, shape을 정의 | . | 다음과 같은 구조로 모델이 저장됨 | . assets/ assets.extra/ variables/ variables.data-?????-of-????? variables.index saved_model.pb . 참고2: Seldon Core Inference Graph(Pipeline) . . https://docs.seldon.io/projects/seldon-core/en/stable/graph/inference-graph.html | https://www.slideshare.net/seldon_io/seldon-deploying-models-at-scale (p28) | .",
            "url": "https://everlearningemployee.github.io/blog/post/KFServing.html",
            "relUrl": "/post/KFServing.html",
            "date": " • May 15, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Git Authentication",
            "content": "GitHub Error: Authentication Failed from the Command Line . 사용자 Settings &gt; Developer settings &gt; Personal access tokens | . | Git pull/push 시 Password 물어보지 않도록 설정하기(credential.helper) . git config credential.helper store . | .",
            "url": "https://everlearningemployee.github.io/blog/post/git-authentication.html",
            "relUrl": "/post/git-authentication.html",
            "date": " • Mar 14, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Ubuntu에 Docker 설치",
            "content": "출처: How To Install Docker On Ubuntu 18.04 Bionic Beaver . sudo apt-get update sudo apt-get remove docker docker-engine docker.io sudo apt install docker.io sudo systemctl start docker sudo systemctl enable docker sudo usermod -aG docker $USER .",
            "url": "https://everlearningemployee.github.io/blog/post/docker-install-on-ubuntu.html",
            "relUrl": "/post/docker-install-on-ubuntu.html",
            "date": " • Mar 14, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Python TDD",
            "content": "Python TDD . 참고자료 . 김정주 Webzen -SlideShare 파이썬 TDD 101 (pdf) | 최명규 - SlideShare - Python Unittest (pdf) | . Python Unit Testing Framework . 5 Python Unit Test Frameworks To Learn In 2019 . unittest 모듈 - 기본 내장 | PyUnit - unittest 예전 이름 | nose - 한물 갔다고 함 | PyTest - 당첨 | coverage - 테스트 커버리지 분석 | Doctest - 특수 목적 . | Google 트렌드: PyTest, nose2, “unittest”에 관한 검색 관심도를 시간, 위치, 인기도순으로 탐색 | . PyTest . PyTest Tutorial: What is, Install, Fixture, Assertions . Why use PyTest? | How to install PyTest | First Basic PyTest | Assertions in PyTest | How pytest identifies the test files and test methods | Run multiple tests from a specific file and multiple files. | Run a subset of entire test | Running tests in parallel :+1: | Pytest fixtures | Parameterized tests :+1: | Xfail / Skip tests | Results XML | A pytest framework testing an API | . Python 테스트 시작하기 . [Python] how to use pytest &amp; mock &amp; fixture . unittest vs pytest .",
            "url": "https://everlearningemployee.github.io/blog/post/hello-pytest.html",
            "relUrl": "/post/hello-pytest.html",
            "date": " • Mar 12, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Kafka를 공부해보자",
            "content": ". PreStop Hook . 구현 필요 . Consumer Group / Partition . Kafka 운영자가 말하는 Kafka Consumer Group 컨슈머 그룹 별로 각각 offset이 유지됨 | 한 번 늘린 Partition은 줄일 수 없음 | 갯수(Partition) &gt; 갯수(Consumer): 어쨌든 일 함. 특정 Consumer로 일이 쏠림 | . | 갯수(Partition) &lt; 갯수(Consumer) 노는 Consumr 생심. 이런 상황 절대 허용할 수 없음 ML 적용 전략 . | . | . | K8s에 ML Logic Consumer Pod가 배포됐다고 치자 . | Consumer Group은 업무별로 1개 . 중복 처리 X이므로 여러 Consumer들이 Offset을 공유해야함 | . | 갯수(Parition)과 갯수(Cousumer ) 매핑 . partition은 consumming 과정이 동기인 듯 . 추정의 이유: 1개의 consumer는 1개 이상의 partition에 붙을 수 있으나 | . | 1개의 partition은 1개의 consumer만 담당 | 무조건 갯수(Partition) &gt;= 갯수(Consumer)로 구성 필요 | ML컨수머는 롱트랜잭션이므로 | . | 1안) 갯수(Partition) = 갯수(Consumer): 1대 1로 갯수를 맞춤 . Consumer Pod를 Scaling 하지 않음 (Min == Max) 장점: 확실 | . | 단점: Pod 리소스 점유 아까워 | . | 2안) 갯수(Partition) = Max(갯수(Consumer)) Consumer Pod를 Scaling 함 장점: Pod 갯수 필요한 만큼 까지만 떠 있음 | . | 단점: 업무 특성 상, Scale Out 시 모델 리스토어를 위하여 Pod ready 시간이 수십초~수분 소요 예상 ← 적절한 선택이 아님 | . | 3안) Parition과 Cousumer 갯수는 테스트로 적정치 선정 Parition과 Cousumer의 갯수 매핑 자체는 실질적으로 의미가 없음 . | 전제: Partition에 대한 메시지 배분이 라운드로빈이 아니라, 대기열이 가장 짧은 partition 우선 ← Custom Partitioner 구현 필요? ← 이미 준비되어있는 선택할 수 있는 Partitioner 유형이 있을 듯 . Producer 생성 시, partitionerType 설정 . default = 0, random = 1, cyclic = 2, keyed = 3, custom = 4 | . | https://github.com/SOHU-Co/kafka-node/issues/1094 . | Parition과 Cousumer 각각의 갯수 자체가 의미 있음 . | 구찮… 3)안은 못 쓰겠다. . | . | . | . | . 이슈 . Partitioner Type . Producer 설정임 property: partitioner.class (default: kafka.producer.DefaultPartitioner) | . | Why is data not evenly distributed among partitions when a partitioning key is not specified? | . Partition Rebalancing . Rebalancing Kafka partitions - TabMo Labs | Incremental Cooperative Rebalancing in Apache Kafka: Why Stop the World When You Can Change It? | . Rebalancing 지연 . 카프카 컨슈머 애플리케이션 배포 전략 - 11번가 사례 | 그룹 내 특정 컨슈머가 poll 메소드를 호출을 지연 | 모든 컨슈머가 poll 해야 rebalancing 진행 | . NiFi 연동 . PublishKafka Partitioner class에 아래 2개 밖에 없음 RoundRobinPartitioner Messages will be assigned partitions in a round-robin fashion, sending the first message to Partition 1, the next Partition to Partition 2, and so on, wrapping as necessary. | DefaultPartitioner | . | . | . Consumer Option . Kafka - Kafka Consumer(카프카 컨슈머) Java&amp;CLI - 코딩스타트 | . Option 내용 컨수머 설정 . bootstrap.servers | 호스트와 포트 정보로 구성된 리스트 |   | . group.id | 컨슈머 그룹 식별자 | 업무별 1개 | . auto.offset.reset | 오프셋이 없거나 현재 오프셋이 더 이상 존재하지 않은 경우 (earliest가장초기/latest마지막/none에러) | latest | . fetch.min.bytes | 한번에 가져올 수 있는 최소 데이터 사이즈이다. 만약 지정한 사이즈보다 작은 경우, 요청에 대해 응답하지 않고 데이터가 누적될 때까지 기다린다 | 뭐지? 확인 필요. 작아야하나? | . fetch.max.bytes | 한번에 가져올 수 있는 최대 데이터 사이즈 | 확인 필요. 별로 안 커도 될듯 | . request.timeout.ms | 요청에 대해 응답을 기다리는 최대 시간 | 뭐지? 확인 필요. 별로 안 커도 될듯 | . session.timeout.ms | 컨슈머와 브로커사이의 세션 타임 아웃시간. 브로커가 컨슈머가 살아있는 것으로 판단하는 시간(기본값 10초) | 롱트랜잭션이므로 충분히 길게 | . hearbeat.interval.ms | 그룹 코디네이터에게 얼마나 자주 KafkaConsumer poll() 메소드로 하트비트를 보낼 것인지 조정한다. session.timeout.ms와 밀접한 관계가 있으며 session.timeout.ms보다 낮아야한다. 일반적으로 1/3 값정도로 설정한다.(기본값 3초) | 이거이거 확인 필요. 우리는 롱트랜잭션 | . max.poll.records | 단일 호출 poll()에 대한 최대 레코드 수를 조정한다. 이 옵션을 통해 애플리케이션이 폴링 루프에서 데이터를 얼마나 가져올지 양을 조정할 수 있다 | 뭐지? | . max.poll.interval.ms | 컨슈머가 살아있는지를 체크하기 위해 하트비트를 주기적으로 보내는데, 컨슈머가 계속해서 하트비트만 보내고 실제로 메시지를 가져가지 않는 경우가 있을 수도 있다. 이러한 경우 컨슈머가 무한정 해당 파티션을 점유할 수 없도록 주기적으로 poll을 호출하지 않으면 장애라고 판단하고 컨슈머 그룹에서 제외한 후 다른 컨슈머가 해당 파티션에서 메시지를 가져갈 수 있게한다. | 이거이거 확인 필요. 우리는 롱트랜잭션 | . # Kafka 토픽 topic: diff-ai # 업무단위: 정책 상 토픽과 1:1 group_id: mymyGrp # Kafka 서버 bootstrap_servers: localhost:9092 # 오프셋이 없거나 현재 오프셋이 더 이상 존재하지 않은 경우 # earliest:가장초기, latest마지막, none:에러 auto_offset_reset: latest # 컨슈머와 브로커사이의 세션 타임 아웃시간 (초). 브로커가 컨슈머가 살아있는 것으로 판단하는 시간 # ML컨수머는 롱트랜잭션이므로 충분히 길게 설정할 것 session_timeout_ms: 1200 # 롱트랜잭션이며 새로 추가되는 pod가 메시지를 즉시 받아올 수 있도록 1로 설정 max_poll_records: 1 . Hello Kafka . Topic 만들기 . kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 4 --topic diff-ai kafka-topics.bat --zookeeper localhost:2181 --list . Producer 콘솔 기동 . kafka-console-producer --broker-list localhost:9092 --topic diff-ai kafka-console-producer --broker-list localhost:9092 --topic mymy-A &lt; .. .. .. Test TestData short_input.txt . Consumer 콘솔 기동 . kafka-console-consumer --bootstrap-server localhost:9092 --topic diff-ai --group mymyGrp kafka-console-consumer --bootstrap-server loclahost:9092 --topic mymy-B --group mymyGrp . Topic alter . kafka-topics --alter --zookeeper localhost:2181 --topic diff-ai --partitions 4 . Kafka port: 9092 | Zookeeper port: 2181 . | Hello world in Kafka using Python - Timber.io | . Python Lib . 구글 트랜드 결과 kafka-python &gt; PyKafka &gt; confluent-kafka-python . | 처리속도 비교 . | Kafka Python client 성능 테스트 (원본자료: Python Kafka Client Benchmarking 2016-06-15) . | https://kafka-python.readthedocs.io/en/master/apidoc/modules.html . | kafka-python 헬로우월드 . Consumer . from kafka import KafkaConsumer import time consumer = KafkaConsumer(&#39;diff-ai&#39;, group_id=&#39;mymyGrp&#39;, bootstrap_servers=&#39;localhost:9092&#39;) for message in consumer: print(&quot; n&quot;+&quot;=&quot;*60) print(message.value) print(&quot;-&quot;*60) #time.sleep(1) consumer.close() . | . | . 모니터링 . Apache kafka 모니터링을 위한 Metrics 이해 및 최적화 방안 | Burrow https://github.com/linkedin/Burrow | Kafka Consumer Lag 모니터링, Burrow를 알아보자 (1) | Monitoring Kafka with Burrow - Part 1 - Cloudera Community | . | Apache ZooKeeper 소개 - SlideShare | .",
            "url": "https://everlearningemployee.github.io/blog/post/hello-kafka.html",
            "relUrl": "/post/hello-kafka.html",
            "date": " • Mar 12, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Uncaught Exception Trace",
            "content": "Uncaught Exception Trace . import sys import traceback def exception_hook(type, value, tb): logging.error(&#39;=&#39; * 80) logging.error(f&#39;Type: {type}&#39;) logging.error(f&#39;Value: {value}&#39;) t = traceback.format_exception(type, value, tb) t = [i.rstrip().split(&#39; n&#39;) for i in t] for i in sum(t, []): logging.error(i) logging.error(&#39;-&#39; * 80) sys.excepthook = exception_hook 1 / 0 . 전체 샘플 코드 . 익셉션 트레이스가 로그에 이렇게 찍힌다 . 2020-03-08 17:51:52 ERROR ================================================================================ 2020-03-08 17:51:52 ERROR Type: &lt;class &#39;IndexError&#39;&gt; 2020-03-08 17:51:52 ERROR Value: tuple index out of range 2020-03-08 17:51:52 ERROR Traceback (most recent call last): 2020-03-08 17:51:52 ERROR File &quot;d:/temp/uncaughtExceptionTrace.py&quot;, line 59, in &lt;module&gt; 2020-03-08 17:51:52 ERROR lumberjack() 2020-03-08 17:51:52 ERROR File &quot;d:/temp/uncaughtExceptionTrace.py&quot;, line 52, in lumberjack 2020-03-08 17:51:52 ERROR bright_side_of_death() 2020-03-08 17:51:52 ERROR File &quot;d:/temp/uncaughtExceptionTrace.py&quot;, line 56, in bright_side_of_death 2020-03-08 17:51:52 ERROR return tuple()[0] 2020-03-08 17:51:52 ERROR IndexError: tuple index out of range 2020-03-08 17:51:52 ERROR -- . Catching every single exception with Python | 파이썬 공식 자습서 - 8. 에러와 예외 | 파이썬을 이용한 전문적인 오류 처리 | .",
            "url": "https://everlearningemployee.github.io/blog/post/uncaughtExceptionTrace.html",
            "relUrl": "/post/uncaughtExceptionTrace.html",
            "date": " • Mar 8, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Korbit 트레이딩봇 - 밀림 사자 Leo",
            "content": "Leo - Korbit 트레이딩봇 . 배경지식 . 리밸런싱 . [기고] 수익률 높이는 효과적인 리밸런싱 전략 | 자산배분전략을 자주 강조하는 이유 : 장기 성과의 중요 | 자산의 리밸런싱(rebalancing) | . 가상화폐 거래소 코빗 . 코빗 거래수수료 | 거래수수료 구분 코빗은 더이상 Taker/Maker 수수료를 구분하지 않는다. 신경 안 써도 됨 | Taker 주문 : 즉시 체결되는 주문 시장가로 주문 | 지정가 주문 시, 이미 오더북에 올라와있는 주문과 동일한 금액으로 주문 | 지정가 매수 주문 시, 체결 가능한 호가보다 높은 가격으로 주문 최고 매수호가 &lt; 매수주문가 → 비싸게 사겠다고 하니까 즉시 체결 | . | 지정가 매도 주문 시, 체결 가능한 호가보다 낮은 가격으로 주문 최저 매도호가 &gt; 매도주문가 → 싸게 팔겠다고 하니까 즉시 체결 | . | . | Maker 주문 : 즉시 체결되지 않는 주문 지정가 매수 주문 시, 체결 가능한 호가보다 낮은 가격으로 주문 최고 매수호가 &gt; 매수주문가 → 싸게 사겠다고 하는 무리 중 하나 | . | 지정가 매도 주문 시, 체결 가능한 호가보다 높은 가격으로 주문 최저 매도호가 &lt; 매도주문가 → 비싸게 팔겠다고 하는 무리 중 하나 | . | . | . | . 용어 . 최근내주문체결가: 나의 주문 중 마지막으로 체결된 거래의 거래가 | 목표 밸런싱비율: “코인 평가금액 : 예수금잔고”의 목표 비율 | 거래트리거링가격변동포인트: 이 %포인트 만큼 체결가 변동이 일어나면 리밸런싱한다 | 제약조건 tick_size 호가단위 | min_price 최소 주문가 | order_min_size 최소 주문량 | max_price 최대 주문가 | order_max_size 최대 주문량 | . | 수수료 volume 해당 통화쌍의 30일간의 거래량(KRW) | maker_fee 베이시스 포인트(BPS - 1/100 퍼센트 기준)로 표기된 maker 거래 수수료율 | taker_fee 베이시스 포인트(BPS - 1/100 퍼센트 기준)로 표기된 taker 거래 수수료율 | . | . 로직 . . 주문가/주문량 산출 . 파라미터/변수 . 입력 입력값 $b$ 목표 밸런싱비율 | $t$ 거래트리거링가격변동포인트 | . | 체결된 주문내역 $p_f$ 최근내주문체결가 | . | 잔고 조회 $a_i$ 코인보유량 | $v_c$ 현금(예수금잔고) | . | env constans (제약조건) $a_m$ 최소주문량 | . | 시장 현황 상세정보 bid: 최고 매수호가 현재 매수 주문 중 가장 높은 가격 | ask: 최저 매도호가 현재 매도 주문 중 가장 낮은 가격 | . | . | . | 중간값 $v_e$ 거래직전 평가액 | $v_o$ 주문금액 | . | 리턴 $p_o$ 주문가 | $a_o$ 주문량 | . | . 로직 . 매수 . 목표밸런싱비율 $b$ 는 입력값으로 고정이다 . b=ve+vovc−vob = {v_e + v_o over v_c - v_o}b=vc​−vo​ve​+vo​​ . 여기서 . vo=ao⋅pov_o = a_o cdot p_ovo​=ao​⋅po​ . ve=ai⋅pov_e = a_i cdot p_ove​=ai​⋅po​ . 따라서 주문량 $a_o$는 . ao=b⋅vc−po⋅aipo⋅(1+b)a_o = { b cdot v_c - p_o cdot a_i over p_o cdot (1 + b) }ao​=po​⋅(1+b)b⋅vc​−po​⋅ai​​ . 여기서 주문가 $p_o$는 . po=pf⋅(1−t)p_o = p_f cdot (1 - t)po​=pf​⋅(1−t) . 만약 주문량 $a_o$이 최소주문량 $a_m$보다 작다면 . ao&lt;ama_o &lt; a_mao​&lt;am​ . 주문량 $a_o$를 최소주문량 $a_m$으로 설정한다 . ao:=ama_o := a_mao​:=am​ . 이 때 주문가 $p_o$는 . po=b⋅vcai+am⋅(1+b)p_o = { b cdot v_c over a_i + a_m cdot ( 1 + b ) }po​=ai​+am​⋅(1+b)b⋅vc​​ . 매도 . 목표밸런싱비율 $b$ 는 입력값으로 고정이다 . b=ve−vovc+vob = {v_e - v_o over v_c + v_o}b=vc​+vo​ve​−vo​​ . 여기서 . vo=ao⋅pov_o = a_o cdot p_ovo​=ao​⋅po​ . ve=ai⋅pov_e = a_i cdot p_ove​=ai​⋅po​ . 따라서 주문량 $a_o$는 . ao=po⋅ai−b⋅vcpo⋅(1+b)a_o = { p_o cdot a_i - b cdot v_c over p_o cdot (1 + b) }ao​=po​⋅(1+b)po​⋅ai​−b⋅vc​​ . 여기서 주문가 $p_o$는 . po=pf⋅(1+t)p_o = p_f cdot (1 + t)po​=pf​⋅(1+t) . 만약 주문량 $a_o$이 최소주문량 $a_m$보다 작다면 . ao&lt;ama_o &lt; a_mao​&lt;am​ . 주문량 $a_o$를 최소주문량 $a_m$으로 설정한다 . ao:=ama_o := a_mao​:=am​ . 이 때 주문가 $p_o$는 . po=b⋅vcai−am⋅(1+b)p_o = { b cdot v_c over a_i - a_m cdot ( 1 + b) }po​=ai​−am​⋅(1+b)b⋅vc​​ . 로깅 . 주문 . 매수주문, 매도주문 호출 성공 후 로깅 . 주문ID (매수주문, 매도주문) | 매도매수구분 (입력값) | 주문가 (주문가/주문량 산출 로직 리턴값) | 주문량 (주문가/주문량 산출 로직 리턴값) | 산출베이스체결ID (체결된 주문내역) | 주문가/주문량 산출 로직 입력값 $b$ 목표 밸런싱비율 (입력값) | $t$ 거래트리거링가격변동포인트 (입력값) | $p_f$ 최근내주문체결가 (체결된 주문내역) | $a_i$ 코인보유량 (잔고 조회) | $v_c$ 현금(예수금잔고) (잔고 조회) | bid: 최고 매수호가 현재 매수 주문 중 가장 높은 가격 (시장 현황 상세정보) | ask: 최저 매도호가 현재 매도 주문 중 가장 낮은 가격 (시장 현황 상세정보) | last: 최종 체결 가격 (시장 현황 상세정보) | . | . 체결 . 체결된 주문내역 확인 후 로깅 . 그냥 json 그대로 저장할까? . 체결된 주문내역 리턴값 체결ID | 매도매수구분 | 체결시각 | 수수료 통화: 매수 시 코인, 매도 시 krw | 수량 | . | 주문ID | 체결가 통화 | 수량 | . | 체결량 통화 | 수량 | . | . | 잔고 조회 리턴값 코인보유량 | 현금(예수금잔고) | . | . Git . https://github.com/everlearningemployee/leo.git .",
            "url": "https://everlearningemployee.github.io/blog/post/leo.html",
            "relUrl": "/post/leo.html",
            "date": " • Mar 7, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "파이썬 기초 5종 세트!! [설치, 헬로우월드, VSCode, pip, 가상환경] 이 모든 것을 한 영상에!!",
            "content": "파이썬 기초 5종 세트!! . 실습 시나리오 + 코드 .",
            "url": "https://everlearningemployee.github.io/blog/post/hello-python.html",
            "relUrl": "/post/hello-python.html",
            "date": " • Nov 30, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "월출봉에 달 뜨거든 날 불러주오 .",
          "url": "https://everlearningemployee.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://everlearningemployee.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}